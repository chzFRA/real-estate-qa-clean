import os
from llm_utils import call_model

# è‡ªåŠ¨é€‰å– texts_clean æ–‡ä»¶å¤¹ä¸‹ç¬¬ä¸€ä¸ª .txt æ–‡ä»¶
INPUT_DIR = "texts_clean"
def find_first_txt_file(input_dir):
    for filename in os.listdir(input_dir):
        if filename.endswith(".txt"):
            return os.path.join(input_dir, filename)
    return None

# è¯»å–ä¸€ä¸ª txt æ–‡ä»¶ï¼Œå–å‰ 2000 å­—
def load_sample_chunk(filepath, max_len=2000):
    with open(filepath, "r", encoding="utf-8") as f:
        text = f.read()
    return text[:max_len]

def main():
    test_txt_path = find_first_txt_file(INPUT_DIR)
    if not test_txt_path:
        print("âŒ æœªåœ¨ texts_clean æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°ä»»ä½• .txt æ–‡ä»¶ï¼")
        return

    print(f"ğŸ” æ­£åœ¨è¯»å–æ–‡ä»¶ï¼š{test_txt_path}")
    chunk = load_sample_chunk(test_txt_path)

    # æ„é€ æç¤ºè¯
    prompt = f"""ä½ æ˜¯ä¸€åæ³•å¾‹ä¸“å®¶,é˜…è¯»ä»¥ä¸‹æ³•å¾‹æ³•è§„æ¡æ–‡,ç”Ÿæˆ3ä¸ªæ™®é€šæˆ¿åœ°äº§ç”¨æˆ·å¯èƒ½ä¼šé—®çš„é—®é¢˜,å¹¶å¯¹æ¯ä¸ªé—®é¢˜æ ¹æ®æ¡æ–‡è¿›è¡Œä¸“ä¸šã€ç®€æ´çš„å›ç­”,å›ç­”ä¸è¦æ­»æ¿å¹¶ä¸”ä½“ç°å‡ºdiversityå’Œä¸ªæ€§åŒ–ã€‚

æ¡æ–‡å¦‚ä¸‹ï¼š
{chunk}

è¯·è¾“å‡ºå¦‚ä¸‹æ ¼å¼ï¼š
Q1: ...
A1: ...
Q2: ...
A2: ...
Q3: ...
A3: ...
"""

    print("\nğŸ“¨ æ­£åœ¨è°ƒç”¨æ¨¡å‹ç”Ÿæˆé—®ç­”...")
    result = call_model(prompt, model="deepseek")
    print("\nğŸ“‹ æ¨¡å‹è¿”å›å†…å®¹å¦‚ä¸‹ï¼š\n")
    print(result)

if __name__ == "__main__":
    main()
